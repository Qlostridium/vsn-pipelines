nextflow.preview.dsl=2

import java.nio.file.Paths

if(!params.containsKey("test")) {
  binDir = "${workflow.projectDir}/src/utils/bin/"
} else {
  binDir = ""
}

process SC__FILE_CONVERTER {
    echo true
  cache 'deep'
  container params.sc.scanpy.container
  clusterOptions "-l nodes=1:ppn=2 -l pmem=30gb -l walltime=1:00:00 -A ${params.global.qsubaccount}"
  publishDir "${params.outdir}/data/intermediate", mode: 'symlink', overwrite: true

  input:
    tuple val(id), file(f)
  output:
    tuple val(id), file("${id}.SC__FILE_CONVERTER.${params.off}")
  script:
    switch(params.iff) {
      case "10x_mtx":
        // Check if output was generated with CellRanger v2 or v3
        f_cellranger_outs_v2 = file("${f.toRealPath()}/${params.useFilteredMatrix ? "filtered" : "raw"}_gene_bc_matrices/")
        f_cellranger_outs_v3 = file("${f.toRealPath()}/${params.useFilteredMatrix ? "filtered" : "raw"}_feature_bc_matrix")
        if(f_cellranger_outs_v2.exists()) {
          genomes = f_cellranger_outs_v2.list()
          if(genomes.size() > 1 || genomes.size() == 0) {
            throw new Exception("None or multiple genomes detected for the output generated by CellRanger v2. Selecting custom genome is currently not implemented. Found: ${genomes}")
          } else {
            f_cellranger_outs_v2 = file(Paths.get(f_cellranger_outs_v2.toString(), genomes[0]))
          }
          f = f_cellranger_outs_v2
        } else if(f_cellranger_outs_v3.exists()) {
          f = f_cellranger_outs_v3
        }
        break;
      case "csv":
        break;
      case "tsv":
        break;
      default:
        throw new Exception("The given input format ${params.iff} is not recognized.")
        break;
    }
    """
    ${binDir}sc_file_converter.py \
       --input-format $params.iff \
       --output-format $params.off ${f} "${id}.SC__FILE_CONVERTER.${params.off}"
    """
}

process SC__FILE_CONVERTER_HELP {
  container params.sc.scanpy.container
  output:
    stdout()
  script:
    """
    ${binDir}sc_file_converter.py -h | awk '/-h/{y=1;next}y'
    """
}

process SC__FILE_CONCATENATOR() {

  cache 'deep'
  container params.sc.scanpy.container
  clusterOptions "-l nodes=1:ppn=2 -l pmem=30gb -l walltime=1:00:00 -A ${params.global.qsubaccount}"
  publishDir "${params.outdir}/data/intermediate", mode: 'symlink', overwrite: true

  input:
    file("*")
  output:
    tuple val(params.project_name), file("${params.project_name}.SC__FILE_CONCATENATOR.${params.off}")
  script:
    """
    ${binDir}sc_file_concatenator.py \
      --file-format $params.off \
      ${(params.containsKey('join')) ? '--join ' + params.join : ''} \
      --output "${params.project_name}.SC__FILE_CONCATENATOR.${params.off}" *
    """
}

process SC__STAR_CONCATENATOR() {

  container "aertslab/sctx-scanpy:0.5.0"
  clusterOptions "-l nodes=1:ppn=2 -l pmem=30gb -l walltime=1:00:00 -A ${params.global.qsubaccount}"
  publishDir "${params.outdir}/data/intermediate", mode: 'symlink', overwrite: true

  input:
    tuple val(id), file(f)
  output:
    tuple val(id), file("${params.project_name}.SC__STAR_CONCATENATOR.${params.off}")
  script:
    id = params.project_name
    """
    ${binDir}sc_star_concatenator.py \
      --stranded $params.stranded \
      --output "${params.project_name}.SC__STAR_CONCATENATOR.${params.off}" $f
    """
}

process SC__FILE_ANNOTATOR() {

  cache 'deep'
  container params.sc.scanpy.container
  clusterOptions "-l nodes=1:ppn=2 -l pmem=30gb -l walltime=1:00:00 -A ${params.global.qsubaccount}"
  publishDir "${params.outdir}/data/intermediate", mode: 'symlink', overwrite: true

  input:
    tuple val(id), file(f)
    file(metaDataFilePath)
  output:
    tuple val(id), file("${id}.SC__FILE_ANNOTATOR.${params.off}")
  script:
    """
    ${binDir}sc_file_annotator.py \
      ${(params.containsKey('type')) ? '--type ' + params.type : ''} \
      ${(params.containsKey('metaDataFilePath')) ? '--meta-data-file-path ' + metaDataFilePath.getName() : ''} \
      $f \
      "${id}.SC__FILE_ANNOTATOR.${params.off}"
    """
}

process SC__PUBLISH_H5AD {

    clusterOptions "-l nodes=1:ppn=2 -l pmem=30gb -l walltime=1:00:00 -A ${params.global.qsubaccount}"
    publishDir "${params.outdir}/data", mode: 'link', overwrite: true

    input:
        tuple val(id), file(fIn)
        val(fOutSuffix)
    output:
        tuple val(id), file("${id}.${fOutSuffix}.h5ad")
    script:
    """
    ln -s ${fIn} "${id}.${fOutSuffix}.h5ad"
    """
}
